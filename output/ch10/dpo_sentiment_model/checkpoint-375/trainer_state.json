{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 375,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "grad_norm": 0.32494089007377625,
      "learning_rate": 4.879999999999999e-07,
      "logits/chosen": 15.1458740234375,
      "logits/rejected": 15.139383316040039,
      "logps/chosen": -1.8725188970565796,
      "logps/rejected": -2.153320789337158,
      "loss": 0.6928,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": 0.0023945567663758993,
      "rewards/margins": 0.0008017636137083173,
      "rewards/rejected": 0.0015927935019135475,
      "step": 10
    },
    {
      "epoch": 0.16,
      "grad_norm": 3.7481279373168945,
      "learning_rate": 4.746666666666667e-07,
      "logits/chosen": 15.171185493469238,
      "logits/rejected": 15.117525100708008,
      "logps/chosen": -1.9509952068328857,
      "logps/rejected": -2.1266160011291504,
      "loss": 0.6924,
      "rewards/accuracies": 0.6000000238418579,
      "rewards/chosen": 0.00143813609611243,
      "rewards/margins": 0.0014612816739827394,
      "rewards/rejected": -2.3145625164033845e-05,
      "step": 20
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.4811596870422363,
      "learning_rate": 4.613333333333333e-07,
      "logits/chosen": 15.165945053100586,
      "logits/rejected": 15.120570182800293,
      "logps/chosen": -1.8823343515396118,
      "logps/rejected": -2.1277194023132324,
      "loss": 0.6926,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.0019094751914963126,
      "rewards/margins": 0.0012258242350071669,
      "rewards/rejected": 0.0006836509564891458,
      "step": 30
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44145429134368896,
      "learning_rate": 4.48e-07,
      "logits/chosen": 15.176176071166992,
      "logits/rejected": 15.111233711242676,
      "logps/chosen": -1.9789714813232422,
      "logps/rejected": -2.0635077953338623,
      "loss": 0.6933,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.0018631411949172616,
      "rewards/margins": -0.0003001689328812063,
      "rewards/rejected": 0.002163310069590807,
      "step": 40
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.5367095470428467,
      "learning_rate": 4.3466666666666664e-07,
      "logits/chosen": 15.159563064575195,
      "logits/rejected": 15.094372749328613,
      "logps/chosen": -1.9679615497589111,
      "logps/rejected": -2.1475296020507812,
      "loss": 0.6939,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.001179728307761252,
      "rewards/margins": -0.0014790772693231702,
      "rewards/rejected": 0.0026588060427457094,
      "step": 50
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.3612317740917206,
      "learning_rate": 4.213333333333333e-07,
      "logits/chosen": 15.208704948425293,
      "logits/rejected": 15.148399353027344,
      "logps/chosen": -1.987816572189331,
      "logps/rejected": -2.152660846710205,
      "loss": 0.6923,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 0.002314973156899214,
      "rewards/margins": 0.0018312979955226183,
      "rewards/rejected": 0.00048367492854595184,
      "step": 60
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5850690603256226,
      "learning_rate": 4.0799999999999995e-07,
      "logits/chosen": 15.211616516113281,
      "logits/rejected": 15.121068000793457,
      "logps/chosen": -1.9934427738189697,
      "logps/rejected": -2.1405158042907715,
      "loss": 0.6912,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.0023439170327037573,
      "rewards/margins": 0.0038984299171715975,
      "rewards/rejected": -0.001554513000883162,
      "step": 70
    },
    {
      "epoch": 0.64,
      "grad_norm": 1.3492850065231323,
      "learning_rate": 3.9466666666666665e-07,
      "logits/chosen": 15.160369873046875,
      "logits/rejected": 15.116495132446289,
      "logps/chosen": -1.9727041721343994,
      "logps/rejected": -2.2211556434631348,
      "loss": 0.6915,
      "rewards/accuracies": 0.5,
      "rewards/chosen": 0.003367986995726824,
      "rewards/margins": 0.0033601236063987017,
      "rewards/rejected": 7.863063729018904e-06,
      "step": 80
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.2983249425888062,
      "learning_rate": 3.8133333333333336e-07,
      "logits/chosen": 15.117507934570312,
      "logits/rejected": 15.059962272644043,
      "logps/chosen": -1.9677499532699585,
      "logps/rejected": -2.1450438499450684,
      "loss": 0.6933,
      "rewards/accuracies": 0.5249999761581421,
      "rewards/chosen": 0.001424612826667726,
      "rewards/margins": -0.00014494899369310588,
      "rewards/rejected": 0.0015695620095357299,
      "step": 90
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.3404871225357056,
      "learning_rate": 3.6799999999999996e-07,
      "logits/chosen": 15.139269828796387,
      "logits/rejected": 15.089825630187988,
      "logps/chosen": -1.8940861225128174,
      "logps/rejected": -2.111107349395752,
      "loss": 0.6906,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.0037297680974006653,
      "rewards/margins": 0.005193662829697132,
      "rewards/rejected": -0.0014638949651271105,
      "step": 100
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.661142110824585,
      "learning_rate": 3.5466666666666667e-07,
      "logits/chosen": 15.146467208862305,
      "logits/rejected": 15.131324768066406,
      "logps/chosen": -1.9207080602645874,
      "logps/rejected": -2.0753557682037354,
      "loss": 0.6915,
      "rewards/accuracies": 0.512499988079071,
      "rewards/chosen": 0.004627509508281946,
      "rewards/margins": 0.0033281375654041767,
      "rewards/rejected": 0.001299371593631804,
      "step": 110
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.5347554683685303,
      "learning_rate": 3.413333333333333e-07,
      "logits/chosen": 15.111242294311523,
      "logits/rejected": 15.128747940063477,
      "logps/chosen": -1.9622461795806885,
      "logps/rejected": -2.1454250812530518,
      "loss": 0.6943,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.002089757937937975,
      "rewards/margins": -0.002234587911516428,
      "rewards/rejected": 0.004324345383793116,
      "step": 120
    },
    {
      "epoch": 1.0,
      "eval_logits/chosen": 15.015442848205566,
      "eval_logits/rejected": 14.976730346679688,
      "eval_logps/chosen": -1.718488097190857,
      "eval_logps/rejected": -1.9362465143203735,
      "eval_loss": 0.6915441155433655,
      "eval_rewards/accuracies": 0.5722476840019226,
      "eval_rewards/chosen": 0.006973375100642443,
      "eval_rewards/margins": 0.0032940288074314594,
      "eval_rewards/rejected": 0.0036793460603803396,
      "eval_runtime": 39.1429,
      "eval_samples_per_second": 22.277,
      "eval_steps_per_second": 5.569,
      "step": 125
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.3457916975021362,
      "learning_rate": 3.28e-07,
      "logits/chosen": 15.109466552734375,
      "logits/rejected": 15.072469711303711,
      "logps/chosen": -1.8877531290054321,
      "logps/rejected": -2.132786273956299,
      "loss": 0.6936,
      "rewards/accuracies": 0.42500001192092896,
      "rewards/chosen": 0.004188318271189928,
      "rewards/margins": -0.0007855176809243858,
      "rewards/rejected": 0.004973835777491331,
      "step": 130
    },
    {
      "epoch": 1.12,
      "grad_norm": 1.2490570545196533,
      "learning_rate": 3.146666666666666e-07,
      "logits/chosen": 15.166719436645508,
      "logits/rejected": 15.126609802246094,
      "logps/chosen": -1.8420155048370361,
      "logps/rejected": -2.092179775238037,
      "loss": 0.6896,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.007234563585370779,
      "rewards/margins": 0.007156548090279102,
      "rewards/rejected": 7.801540050422773e-05,
      "step": 140
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5478284358978271,
      "learning_rate": 3.0133333333333333e-07,
      "logits/chosen": 15.11668872833252,
      "logits/rejected": 15.102063179016113,
      "logps/chosen": -1.879636526107788,
      "logps/rejected": -2.0787627696990967,
      "loss": 0.6923,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.005658736918121576,
      "rewards/margins": 0.0018144085770472884,
      "rewards/rejected": 0.003844328224658966,
      "step": 150
    },
    {
      "epoch": 1.28,
      "grad_norm": 2.5375726222991943,
      "learning_rate": 2.88e-07,
      "logits/chosen": 15.109395980834961,
      "logits/rejected": 15.053939819335938,
      "logps/chosen": -1.8502811193466187,
      "logps/rejected": -2.1165688037872314,
      "loss": 0.6904,
      "rewards/accuracies": 0.550000011920929,
      "rewards/chosen": 0.008316630497574806,
      "rewards/margins": 0.005720286164432764,
      "rewards/rejected": 0.0025963447988033295,
      "step": 160
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 1.4559426307678223,
      "learning_rate": 2.7466666666666664e-07,
      "logits/chosen": 15.222834587097168,
      "logits/rejected": 15.159917831420898,
      "logps/chosen": -1.8701198101043701,
      "logps/rejected": -2.0817651748657227,
      "loss": 0.6898,
      "rewards/accuracies": 0.574999988079071,
      "rewards/chosen": 0.009849528782069683,
      "rewards/margins": 0.006865324918180704,
      "rewards/rejected": 0.00298420456238091,
      "step": 170
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5875444412231445,
      "learning_rate": 2.613333333333333e-07,
      "logits/chosen": 15.13578987121582,
      "logits/rejected": 15.064996719360352,
      "logps/chosen": -1.8984177112579346,
      "logps/rejected": -2.1078286170959473,
      "loss": 0.6886,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01081777922809124,
      "rewards/margins": 0.00918657798320055,
      "rewards/rejected": 0.0016312028747051954,
      "step": 180
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.6568546295166016,
      "learning_rate": 2.48e-07,
      "logits/chosen": 15.175732612609863,
      "logits/rejected": 15.145840644836426,
      "logps/chosen": -1.9163973331451416,
      "logps/rejected": -2.152184009552002,
      "loss": 0.6914,
      "rewards/accuracies": 0.4625000059604645,
      "rewards/chosen": 0.005938053131103516,
      "rewards/margins": 0.0037112473510205746,
      "rewards/rejected": 0.002226805780082941,
      "step": 190
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.542773425579071,
      "learning_rate": 2.3466666666666665e-07,
      "logits/chosen": 15.182291030883789,
      "logits/rejected": 15.126615524291992,
      "logps/chosen": -1.849966287612915,
      "logps/rejected": -2.0691287517547607,
      "loss": 0.6882,
      "rewards/accuracies": 0.6625000238418579,
      "rewards/chosen": 0.011661190539598465,
      "rewards/margins": 0.010152854956686497,
      "rewards/rejected": 0.0015083359321579337,
      "step": 200
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.3152260780334473,
      "learning_rate": 2.213333333333333e-07,
      "logits/chosen": 15.220240592956543,
      "logits/rejected": 15.160848617553711,
      "logps/chosen": -1.8616359233856201,
      "logps/rejected": -2.207641839981079,
      "loss": 0.6877,
      "rewards/accuracies": 0.6875,
      "rewards/chosen": 0.01216219924390316,
      "rewards/margins": 0.011008639819920063,
      "rewards/rejected": 0.0011535600060597062,
      "step": 210
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.5962924957275391,
      "learning_rate": 2.0799999999999998e-07,
      "logits/chosen": 15.12390422821045,
      "logits/rejected": 15.053807258605957,
      "logps/chosen": -1.864211082458496,
      "logps/rejected": -2.2154948711395264,
      "loss": 0.6878,
      "rewards/accuracies": 0.637499988079071,
      "rewards/chosen": 0.012649737298488617,
      "rewards/margins": 0.01081870123744011,
      "rewards/rejected": 0.001831035828217864,
      "step": 220
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 2.586916446685791,
      "learning_rate": 1.9466666666666664e-07,
      "logits/chosen": 15.176910400390625,
      "logits/rejected": 15.110099792480469,
      "logps/chosen": -1.8290016651153564,
      "logps/rejected": -2.1406660079956055,
      "loss": 0.6872,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.012659311294555664,
      "rewards/margins": 0.012250355444848537,
      "rewards/rejected": 0.0004089543654117733,
      "step": 230
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.7333926558494568,
      "learning_rate": 1.8133333333333334e-07,
      "logits/chosen": 15.155285835266113,
      "logits/rejected": 15.130017280578613,
      "logps/chosen": -1.9393527507781982,
      "logps/rejected": -2.175293445587158,
      "loss": 0.69,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.00891810841858387,
      "rewards/margins": 0.006422077305614948,
      "rewards/rejected": 0.0024960327427834272,
      "step": 240
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.767040491104126,
      "learning_rate": 1.68e-07,
      "logits/chosen": 15.188156127929688,
      "logits/rejected": 15.120569229125977,
      "logps/chosen": -1.8231414556503296,
      "logps/rejected": -2.076320171356201,
      "loss": 0.6859,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.013584500178694725,
      "rewards/margins": 0.014816378243267536,
      "rewards/rejected": -0.001231880160048604,
      "step": 250
    },
    {
      "epoch": 2.0,
      "eval_logits/chosen": 14.969834327697754,
      "eval_logits/rejected": 14.934253692626953,
      "eval_logps/chosen": -1.6387535333633423,
      "eval_logps/rejected": -1.91000235080719,
      "eval_loss": 0.6889253258705139,
      "eval_rewards/accuracies": 0.5997706651687622,
      "eval_rewards/chosen": 0.014946848154067993,
      "eval_rewards/margins": 0.00864306092262268,
      "eval_rewards/rejected": 0.006303786765784025,
      "eval_runtime": 31.3185,
      "eval_samples_per_second": 27.843,
      "eval_steps_per_second": 6.961,
      "step": 250
    },
    {
      "epoch": 2.08,
      "grad_norm": 1.3211772441864014,
      "learning_rate": 1.5466666666666668e-07,
      "logits/chosen": 15.181432723999023,
      "logits/rejected": 15.135846138000488,
      "logps/chosen": -1.8788578510284424,
      "logps/rejected": -2.0419223308563232,
      "loss": 0.6895,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.01230781152844429,
      "rewards/margins": 0.007592229638248682,
      "rewards/rejected": 0.004715581424534321,
      "step": 260
    },
    {
      "epoch": 2.16,
      "grad_norm": 2.498363494873047,
      "learning_rate": 1.4133333333333333e-07,
      "logits/chosen": 15.150487899780273,
      "logits/rejected": 15.125368118286133,
      "logps/chosen": -1.8080651760101318,
      "logps/rejected": -2.1297318935394287,
      "loss": 0.6873,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.01316978968679905,
      "rewards/margins": 0.011990985833108425,
      "rewards/rejected": 0.001178803388029337,
      "step": 270
    },
    {
      "epoch": 2.24,
      "grad_norm": 1.4477689266204834,
      "learning_rate": 1.28e-07,
      "logits/chosen": 15.179681777954102,
      "logits/rejected": 15.115022659301758,
      "logps/chosen": -1.819728136062622,
      "logps/rejected": -2.1336915493011475,
      "loss": 0.6837,
      "rewards/accuracies": 0.6499999761581421,
      "rewards/chosen": 0.01791505515575409,
      "rewards/margins": 0.01940048858523369,
      "rewards/rejected": -0.0014854337787255645,
      "step": 280
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.5659453868865967,
      "learning_rate": 1.1466666666666666e-07,
      "logits/chosen": 15.169116020202637,
      "logits/rejected": 15.129629135131836,
      "logps/chosen": -1.7902123928070068,
      "logps/rejected": -2.1539742946624756,
      "loss": 0.6874,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.01325927209109068,
      "rewards/margins": 0.011889943853020668,
      "rewards/rejected": 0.0013693284709006548,
      "step": 290
    },
    {
      "epoch": 2.4,
      "grad_norm": 1.3459742069244385,
      "learning_rate": 1.0133333333333333e-07,
      "logits/chosen": 15.155901908874512,
      "logits/rejected": 15.095845222473145,
      "logps/chosen": -1.896458387374878,
      "logps/rejected": -2.1713175773620605,
      "loss": 0.6862,
      "rewards/accuracies": 0.612500011920929,
      "rewards/chosen": 0.012619247660040855,
      "rewards/margins": 0.014297339133918285,
      "rewards/rejected": -0.0016780899604782462,
      "step": 300
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.6580245494842529,
      "learning_rate": 8.8e-08,
      "logits/chosen": 15.17138957977295,
      "logits/rejected": 15.09547233581543,
      "logps/chosen": -1.7833244800567627,
      "logps/rejected": -2.13262939453125,
      "loss": 0.6837,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.01413638610392809,
      "rewards/margins": 0.019453251734375954,
      "rewards/rejected": -0.005316863767802715,
      "step": 310
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.3666354417800903,
      "learning_rate": 7.466666666666667e-08,
      "logits/chosen": 15.149622917175293,
      "logits/rejected": 15.105209350585938,
      "logps/chosen": -1.8215644359588623,
      "logps/rejected": -2.133519172668457,
      "loss": 0.6845,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.014928159303963184,
      "rewards/margins": 0.01793636381626129,
      "rewards/rejected": -0.0030082035809755325,
      "step": 320
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7669362425804138,
      "learning_rate": 6.133333333333333e-08,
      "logits/chosen": 15.212495803833008,
      "logits/rejected": 15.129081726074219,
      "logps/chosen": -1.7819640636444092,
      "logps/rejected": -2.1577305793762207,
      "loss": 0.6839,
      "rewards/accuracies": 0.5874999761581421,
      "rewards/chosen": 0.01683119870722294,
      "rewards/margins": 0.019102340564131737,
      "rewards/rejected": -0.002271142089739442,
      "step": 330
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 1.4241398572921753,
      "learning_rate": 4.8e-08,
      "logits/chosen": 15.14964771270752,
      "logits/rejected": 15.072880744934082,
      "logps/chosen": -1.7976396083831787,
      "logps/rejected": -2.180807590484619,
      "loss": 0.6831,
      "rewards/accuracies": 0.625,
      "rewards/chosen": 0.019758567214012146,
      "rewards/margins": 0.020812470465898514,
      "rewards/rejected": -0.0010539008071646094,
      "step": 340
    },
    {
      "epoch": 2.8,
      "grad_norm": 3.8698503971099854,
      "learning_rate": 3.4666666666666666e-08,
      "logits/chosen": 15.167318344116211,
      "logits/rejected": 15.162469863891602,
      "logps/chosen": -1.8405961990356445,
      "logps/rejected": -2.173962354660034,
      "loss": 0.6908,
      "rewards/accuracies": 0.44999998807907104,
      "rewards/chosen": 0.011484337039291859,
      "rewards/margins": 0.005047044716775417,
      "rewards/rejected": 0.006437291856855154,
      "step": 350
    },
    {
      "epoch": 2.88,
      "grad_norm": 2.730168104171753,
      "learning_rate": 2.1333333333333332e-08,
      "logits/chosen": 15.171045303344727,
      "logits/rejected": 15.14452075958252,
      "logps/chosen": -1.8092677593231201,
      "logps/rejected": -2.0927443504333496,
      "loss": 0.6884,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.014723991975188255,
      "rewards/margins": 0.009977745823562145,
      "rewards/rejected": 0.00474624615162611,
      "step": 360
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5863204598426819,
      "learning_rate": 8e-09,
      "logits/chosen": 15.124194145202637,
      "logits/rejected": 15.073351860046387,
      "logps/chosen": -1.8343982696533203,
      "logps/rejected": -2.170128345489502,
      "loss": 0.685,
      "rewards/accuracies": 0.5625,
      "rewards/chosen": 0.017244115471839905,
      "rewards/margins": 0.01684110052883625,
      "rewards/rejected": 0.0004030134587083012,
      "step": 370
    },
    {
      "epoch": 3.0,
      "eval_logits/chosen": 14.994544982910156,
      "eval_logits/rejected": 14.957395553588867,
      "eval_logps/chosen": -1.6482048034667969,
      "eval_logps/rejected": -1.9527157545089722,
      "eval_loss": 0.6873306035995483,
      "eval_rewards/accuracies": 0.5917431116104126,
      "eval_rewards/chosen": 0.014001715928316116,
      "eval_rewards/margins": 0.01196928322315216,
      "eval_rewards/rejected": 0.0020324341021478176,
      "eval_runtime": 39.2066,
      "eval_samples_per_second": 22.241,
      "eval_steps_per_second": 5.56,
      "step": 375
    }
  ],
  "logging_steps": 10,
  "max_steps": 375,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
